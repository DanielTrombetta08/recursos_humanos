import streamlit as st
import uuid
import os
from utils import *
from dotenv import load_dotenv

# Carrega vari√°veis de ambiente
load_dotenv()

# Para deploy, usar st.secrets ao inv√©s de .env
try:
    # Primeiro tenta st.secrets (deploy)
    groq_api_key = st.secrets["GROQ_API_KEY"]
except:
    # Se n√£o encontrar, usa .env (desenvolvimento local)
    groq_api_key = os.getenv("GROQ_API_KEY")

# Definir a vari√°vel para o Groq
os.environ["GROQ_API_KEY"] = groq_api_key

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Triagem e An√°lise de Curr√≠culos", 
    page_icon="üìÑ", 
    layout="wide"
)

# Configura√ß√µes do modelo e arquivos
id_model = "deepseek-r1-distill-llama-70b"
temperature = 0.7
json_file = 'curriculos.json'
path_job_csv = "vagas.csv"

# Carrega o modelo LLM
llm = load_llm(id_model, temperature)

# Defini√ß√£o da vaga (hardcoded)
job = {}
job['title'] = "Desenvolvedor(a) Full Stack"
job['description'] = "Estamos em busca de um(a) Desenvolvedor(a) Full Stack para integrar o time de tecnologia da nossa empresa, atuando em projetos estrat√©gicos com foco em solu√ß√µes escal√°veis e orientadas a dados. O(a) profissional ser√° respons√°vel por desenvolver, manter e evoluir aplica√ß√µes web robustas, al√©m de colaborar com times multidisciplinares para entregar valor cont√≠nuo ao neg√≥cio."
job['details'] = """
Atividades:
- Desenvolver e manter aplica√ß√µes web em ambientes modernos, utilizando tecnologias back-end e front-end.
- Trabalhar com equipes de produto, UX e dados para entender demandas e propor solu√ß√µes.
- Criar APIs, integra√ß√µes e dashboards interativos.
- Garantir boas pr√°ticas de versionamento, testes e documenta√ß√£o.
- Participar de revis√µes de c√≥digo, deploys e melhorias cont√≠nuas na arquitetura das aplica√ß√µes.

Pr√©-requisitos:
- S√≥lidos conhecimentos em Python, JavaScript e SQL.
- Experi√™ncia pr√°tica com frameworks como React, Node.js e Django.
- Familiaridade com versionamento de c√≥digo usando Git.
- Experi√™ncia com servi√ßos de nuvem, como AWS e Google Cloud Platform.
- Capacidade de trabalhar em equipe, com boa comunica√ß√£o e perfil colaborativo.

Diferenciais:
- Conhecimento em Power BI ou outras ferramentas de visualiza√ß√£o de dados.
- Experi√™ncia anterior em ambientes √°geis (Scrum, Kanban).
- Projetos pr√≥prios, contribui√ß√µes open source ou portf√≥lio t√©cnico dispon√≠vel.
- Certifica√ß√µes em nuvem ou √°reas relacionadas √† engenharia de software.
"""

# Schema para extra√ß√£o de dados estruturados
schema = """
{
  "name": "Nome completo do candidato",
  "area": "√Årea ou setor principal que o candidato atua. Classifique em apenas uma: Desenvolvimento, Marketing, Vendas, Financeiro, Administrativo, Outros",
  "summary": "Resumo objetivo sobre o perfil profissional do candidato",
  "skills": ["compet√™ncia 1", "compet√™ncia 2", "..."],
  "education": "Resumo da forma√ß√£o acad√™mica mais relevante",
  "interview_questions": ["Pelo menos 3 perguntas √∫teis para entrevista com base no curr√≠culo, para esclarecer algum ponto ou explorar melhor"],
  "strengths": ["Pontos fortes e aspectos que indicam alinhamento com o perfil ou vaga desejada"],
  "areas_for_development": ["Pontos que indicam poss√≠veis lacunas, fragilidades ou necessidades de desenvolvimento"],
  "important_considerations": ["Observa√ß√µes espec√≠ficas que merecem verifica√ß√£o ou cuidado adicional"],
  "final_recommendations": "Resumo avaliativo final com sugest√µes de pr√≥ximos passos (ex: seguir com entrevista, indicar para outra vaga)",
  "score": 0.0
}
"""

# Campos obrigat√≥rios para valida√ß√£o
fields = [
    "name",
    "area",
    "summary",
    "skills",
    "education",
    "interview_questions",
    "strengths",
    "areas_for_development",
    "important_considerations",
    "final_recommendations",
    "score"
]

# Crit√©rios de pontua√ß√£o
prompt_score = """
Com base na vaga espec√≠fica, calcule a pontua√ß√£o final (de 0.0 a 10.0).
O retorno para esse campo deve conter apenas a pontua√ß√£o final (x.x) sem mais nenhum texto ou anota√ß√£o.
Seja justo e rigoroso ao atribuir as notas. A nota 10.0 s√≥ deve ser atribu√≠da para candidaturas que superem todas as expectativas da vaga.

Crit√©rios de avalia√ß√£o:
1. Experi√™ncia (Peso: 35% do total): An√°lise de posi√ß√µes anteriores, tempo de atua√ß√£o e similaridade com as responsabilidades da vaga.
2. Habilidades T√©cnicas (Peso: 25% do total): Verifique o alinhamento das habilidades t√©cnicas com os requisitos mencionados na vaga.
3. Educa√ß√£o (Peso: 15% do total): Avalie a relev√¢ncia da gradua√ß√£o/certifica√ß√µes para o cargo, incluindo institui√ß√µes e anos de estudo.
4. Pontos Fortes (Peso: 15% do total): Avalie a relev√¢ncia dos pontos fortes (ou alinhamentos) para a vaga.
5. Pontos Fracos (Desconto de at√© 10%): Avalie a gravidade dos pontos fracos (ou desalinhamentos) para a vaga.
"""

# Template do prompt para an√°lise
prompt_template = ChatPromptTemplate.from_template("""
Voc√™ √© um especialista em Recursos Humanos com vasta experi√™ncia em an√°lise de curr√≠culos.
Sua tarefa √© analisar o conte√∫do a seguir e extrair os dados conforme o formato abaixo, para cada um dos campos.
Responda apenas com o JSON estruturado e utilize somente essas chaves. Cuide para que os nomes das chaves sejam exatamente esses.
N√£o adicione explica√ß√µes ou anota√ß√µes fora do JSON.

Schema desejado:
{schema}

---
Para o c√°lculo do campo score:
{prompt_score}

---
Curr√≠culo a ser analisado:
'{cv}'

---
Vaga que o candidato est√° se candidatando:
'{job}'
""")

# Inicializa√ß√£o do estado da sess√£o
if "uploader_key" not in st.session_state:
    st.session_state.uploader_key = str(uuid.uuid4())

if "selected_cv" not in st.session_state:
    st.session_state.selected_cv = None

if "show_confirm" not in st.session_state:
    st.session_state.show_confirm = False

# Salva descri√ß√£o da vaga em CSV
save_job_to_csv(job, path_job_csv)
job_details = load_job(path_job_csv)

# Interface principal - Layout em duas colunas
col1, col2 = st.columns(2)

with col1:
    st.header("Triagem e An√°lise de Curr√≠culos")
    st.markdown("#### Vaga: {}".format(job["title"]))

with col2:
    uploaded_file = st.file_uploader(
        "Envie um curr√≠culo em PDF", 
        type=["pdf"], 
        key=st.session_state.uploader_key,
        help="Fa√ßa upload de um arquivo PDF contendo o curr√≠culo para an√°lise"
    )

# Processamento do upload
if uploaded_file is not None:
    with st.spinner("Analisando o curr√≠culo..."):
        try:
            # Salva arquivo temporariamente
            path = uploaded_file.name
            with open(path, "wb") as f:
                f.write(uploaded_file.read())
            
            # Processa o curr√≠culo
            output, res = process_cv(schema, job_details, prompt_template, prompt_score, llm, path)
            structured_data = parse_res_llm(res, fields)
            
            # Verifica se os dados foram extra√≠dos corretamente
            if structured_data:
                save_json_cv(structured_data, path_json=json_file, key_name="name")
                st.success("‚úÖ Curr√≠culo analisado com sucesso!")
                st.session_state.uploader_key = str(uuid.uuid4())
                
                # Remove arquivo tempor√°rio
                try:
                    os.remove(path)
                except:
                    pass
                
            else:
                st.error("‚ùå Erro ao processar o curr√≠culo. Tente novamente.")
                
        except Exception as e:
            st.error(f"‚ùå Erro durante o processamento: {str(e)}")
            # Remove arquivo tempor√°rio em caso de erro
            try:
                os.remove(path)
            except:
                pass

    # Exibe resultados se os dados foram processados
    if 'structured_data' in locals() and structured_data:
        st.write(show_cv_result(structured_data))
        
        with st.expander("Ver dados estruturados (JSON)"):
            st.json(structured_data)

# Se√ß√£o de curr√≠culos analisados
if os.path.exists(json_file):
    st.subheader("Lista de curr√≠culos analisados", divider="gray")
    
    # Bot√£o "Limpar Tudo" centralizado
    col_clear1, col_clear2, col_clear3 = st.columns([1, 2, 1])
    with col_clear2:
        if st.button(
            "üóëÔ∏è Limpar Tudo", 
            type="secondary", 
            help="Remove todos os curr√≠culos analisados da lista",
            use_container_width=True
        ):
            st.session_state.show_confirm = True
    
    # Modal de confirma√ß√£o
    if st.session_state.get("show_confirm", False):
        st.warning("‚ö†Ô∏è **Aten√ß√£o!** Esta a√ß√£o remover√° permanentemente todos os curr√≠culos analisados.")
        
        col_confirm1, col_confirm2, col_confirm3 = st.columns([1, 1, 1])
        
        with col_confirm1:
            if st.button("‚úÖ Confirmar", type="primary", use_container_width=True):
                if clear_all_cv(json_file):
                    st.success("‚úÖ Todos os curr√≠culos foram removidos com sucesso!")
                    st.session_state.show_confirm = False
                    st.session_state.selected_cv = None  # Limpa curr√≠culo selecionado
                    st.rerun()
                else:
                    st.error("‚ùå Erro ao remover os curr√≠culos. Tente novamente.")
        
        with col_confirm3:
            if st.button("‚ùå Cancelar", use_container_width=True):
                st.session_state.show_confirm = False
                st.rerun()
    
    # Separador visual
    st.markdown("---")
    
    # Lista de curr√≠culos
    try:
        df = display_json_table(json_file)
        
        if not df.empty:
            for i, row in df.iterrows():
                cols = st.columns([1, 3, 1, 5])
                
                with cols[0]:
                    if st.button("Ver detalhes", key=f"btn_{i}"):
                        st.session_state.selected_cv = row.to_dict()
                        st.rerun()
                
                with cols[1]:
                    st.write(f"**Nome:** {row.get('name', '-')}")
                
                with cols[2]:
                    score = row.get('score', 0)
                    if isinstance(score, (int, float)):
                        st.write(f"**Score:** {score:.1f}")
                    else:
                        st.write(f"**Score:** {score}")
                
                with cols[3]:
                    summary = row.get('summary', '-')
                    if len(str(summary)) > 100:
                        summary = str(summary)[:100] + "..."
                    st.write(f"**Resumo:** {summary}")
        else:
            st.info("Nenhum curr√≠culo encontrado na base de dados.")
            
    except Exception as e:
        st.error(f"Erro ao carregar curr√≠culos: {str(e)}")

# Exibi√ß√£o de curr√≠culo selecionado
if st.session_state.selected_cv:
    st.markdown("---")
    st.subheader("Detalhes do Curr√≠culo Selecionado")
    st.write(show_cv_result(st.session_state.selected_cv))
    
    with st.expander("Ver dados estruturados (JSON)"):
        st.json(st.session_state.selected_cv)
    
    # Bot√£o para limpar sele√ß√£o
    if st.button("üîô Voltar √† lista", type="secondary"):
        st.session_state.selected_cv = None
        st.rerun()

# Se√ß√£o de download e visualiza√ß√£o de dados
if os.path.exists(json_file):
    st.markdown("---")
    st.subheader("Exportar Dados", divider="blue")
    
    # Bot√£o de download
    with open(json_file, "r", encoding="utf-8") as f:
        json_data = f.read()
    
    col_download1, col_download2, col_download3 = st.columns([1, 2, 1])
    with col_download2:
        st.download_button(
            label="üì• Baixar arquivo JSON",
            data=json_data,
            file_name=f"curriculos_analisados_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            use_container_width=True,
            help="Baixa todos os curr√≠culos analisados em formato JSON"
        )
    
    # Tabela completa de dados
    st.subheader("Tabela Completa de Dados")
    try:
        df = display_json_table(json_file)
        if not df.empty:
            # Configura a exibi√ß√£o da tabela
            st.dataframe(
                df,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "score": st.column_config.NumberColumn(
                        "Score",
                        help="Pontua√ß√£o do candidato (0.0 a 10.0)",
                        min_value=0.0,
                        max_value=10.0,
                        step=0.1,
                        format="%.1f"
                    ),
                    "name": st.column_config.TextColumn(
                        "Nome",
                        help="Nome completo do candidato",
                        width="medium"
                    ),
                    "area": st.column_config.TextColumn(
                        "√Årea",
                        help="√Årea de atua√ß√£o do candidato",
                        width="small"
                    )
                }
            )
        else:
            st.info("Nenhum dado encontrado para exibi√ß√£o.")
            
    except Exception as e:
        st.error(f"Erro ao exibir tabela: {str(e)}")

# Rodap√© com informa√ß√µes
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666; font-size: 0.8em; padding: 20px 0;'>
        üíº Sistema de Triagem e An√°lise de Curr√≠culos | Desenvolvido com Streamlit e IA
    </div>
    """, 
    unsafe_allow_html=True
)
